fileURL <- "https://data.baltomorecity.gov/api/views/dz54-2aru/rows.csv?accessType=DOWNLOAD"
download.file(fileURL, destfile = "./data/cameras.csv", method = "curl")
install.packages("RMySQL")
library("RMySQL")
install.packages("RMySQL")
install.packages(“RMySQL”, type = “source”)
install.packages("RMySQL", type = "source")
library("RMySQL")
install.packages("RMySQL", type = "source")
install.packages("RMySQL", type = "source")
install.packages("RMySQL", type = "source")
library("RMySQL")
ucscDb <- dbConnect(MySQL(), user="genome", host="genome-mysql.cse.ucsc.edu")
swirl()
library(swirl)
swirl()
ones <- rep(1, nrow(galton))
lm(child ~ ones + parent - 1, galton)
lm(child ~ parent, galton)
lm(child~1, galton)
view(trees)
head(trees)
fit <- lm(Volume ~ Girth + Height + Constant - 1, trees)
tree2 <- eliminate("Girth", trees)
trees2 <- eliminate("Girth", trees)
head(tree2)
head(trees2)
fit2 <- lm(Volume ~ Height + Constant - 1, trees2)
lapply(list(fit, fit2), coef)
swirl()
all <- lm(Fertility ~ ., swiss)
summary(all)
summary(lm(Fertility ~ Agriculture, swiss))
cor(swiss$Examination, swiss$Education)
cor(swiss$Agriculture, swiss$Education)
makelms()
ec <- swiss$Examination + swiss$Catholic
efit <- lm(Fertility ~ .+ec, swiss)
fit$coefficients - efit$coefficients
all$coefficients-efit$coefficients
swirl()
View(InsectSprays)
table(InsectSprays$spray)
6
swirl()
6
dim(InsectSprays)
head(InsectSprays, 15)
sA
sA[, 2]
nrow(sA)
summary(InsectSprays[, 2])
sapply(X = InsectSprays, )
sapply(X = InsectSprays, names )
sapply(InsectSprays,class)
fit <- lm(spray ~ count, InsectSprays)
fit <- lm(count ~ spray, InsectSprays)
summary(fit)$coef
est <- summary(fit)$coef[, 1]
mean(sA)
mean(sB)
nfit <- lm(count ~ spray - 1, InsectSprays)
summary(nfit)$coef
spray2 <- relevel(InsectSprays$spray, "C")
fit2 <- lm(count ~ spray, spray2)
spray2
fit2 <- lm(count ~ spray2, InsectSprays)
summary(fit2)$coef
mean(sC)
(fit$coef[2] - fit$coef[3])/1.6011
dim(hunger)
943
948
names(hunger)
fit <- lm(Numeric ~ Year, hunger)
summary(fit)$coef
lmf <- lm(Numeric ~ Year, subset(hunger, hunger$Sex == "Female"))
lmF <- lm(Numeric[Sex=="Female"] ~ Year[Sex=="Female"],hunger)
lmM <- lm(Numeric[Sex=="Male"] ~ Year[Sex=="Male"],hunger)
lmBoth <- lm(Numeric ~ Year + Sex, hunger)
summary(lmBoth)
lmInter <- lm(Numeric ~ Year + Sex + Sex*Year, hunger)
summary(lmInter)
names(mtcars)
fit <- lm(mpg ~ cyl + wt, mtcars)
summary(fit)
summary(fit)$coef
summary(fit)$coef[1, 2]
summary(fit)$coef[2, 1]
4 * summary(fit)$coef[2, 1]
library(swirl)
swirl()
rgp1()
rgp2()
head(swiss)
mdl <- lm(Fertility~., swiss)
vif(mdl)
mdl <- lm(Fertility~. - Examination, swiss)
mdl2 <- lm(Fertility~. - Examination, swiss)
vif(mdl2)
x1c <- simbias()
apply(x1c, 1, mean)
fit1 <- lm(Fertility~Agriculture, swiss)
fit3 <- lm(Fertility ~ Agriculture + Examination + Education, swiss)
anova(fit1, fit3)
deviance(fit3)
d <- deviance(fit3)/43
n <- (deviance(fit1) - deviance(fit3))/(df.residual(fit1) - df.residual(fit3))
n/d
pf(n/d, 2, 43, lower.tail = FALSE)
shapiro.test(fit3$residuals)
anova(fit1, fit3, fit5, fit6)
swirl()
View(ravenData)
mdl <- glm(ravenWinNum ~ ravenScore, family = binomial, data = ravenData)
lodds <- predict(mdl, data.frame(ravenScore = c(0, 3, 6)))
exp(lodds)/(1+exp(lodds))
summary(mdl)
confint(object = mdl)
exp(confint(mdl))
anova(mdl)
qchisq(0.95, 1)
?mtcars
data(mtcars)
automatic <- subset(mtcars, mtcars$am ==  0)
manual <- subset(mtcars, mtcars$am == 1)
test <- t.test(automatic$mpg, manual$mpg)
test
test$statistic
test$p.value
test$conf.int
test$estimate
test$method
test$null.value
plot(automatic)
plot(automatic$mpg)
hist(automatic$mpg)
summary(lm(mpg ~ factor(am), mtcars))$coeff
summary(lm(mpg ~ factor(am) - 1, mtcars))$coeff
lm(formula = Fertility ~ . + z, data = swiss)
z <- swiss$Agriculture + swiss$Education
lm(Fertility ~ . + z, data = swiss)
summary(lm(Fertility ~ . + z, data = swiss))
boxplot(x = mtcars$mpg, col = red)
boxplot(x = mtcars$mpg, col = "red")
boxplot(formula = mpg ~ factor(am) , data =  mtcars, col = "red")
boxplot(formula = mpg ~ factor(am) , data =  mtcars, col = "red", names = c("Automatic", "Manual"))
boxplot(formula = mpg ~ factor(am) , data =  mtcars, col = "red", names = c("Automatic", "Manual"), outline = TRUE)
boxplot(formula = mpg ~ factor(am) , data =  mtcars, col = "lightblue", names = c("Automatic", "Manual"), outline = TRUE, main = " Compare the automatic and manual transmission over mpg ", xlab = "Transmission", ylab = "Miles/(US) gallon")
fit <- lm(mpg ~ factor(am), mtcars)
library(MASS)
fit <- lm(mpg ~., data = mtcars)
step <- stepAIC(fit, direction = "both")
step$anova
step <- stepAIC(fit, direction = "backward")
step$anova
fit1 <- lm(mpg ~ wt + qsec + factor(am), mtcars)
deviance(fit1)
summary(fit1)
fit2 <- lm(mpg ~ factor(am), mtcars)
deviance(fit2)
summary(fit1)
t.test(fit1)
t.test(mpg ~ factor(am), mtcars)
t.test(mpg ~ factor(am), mtcars,alternative = "greater")
residuals(fit)
fitted(fit)
fit1 <- lm(mpg ~ wt + qsec + am, mtcars)
summary(fit1)
summary(lm(mpg ~ wt + qsec + factor(am), mtcars))
library(MASS); step <- stepAIC(lm(mpg ~., mtcars), direction = "both")
names(step)
step$model
fit$coefficients[2]
fit1$coefficients[2]
fit1 <- lm( mpg ~ factor(am) + wt + qsec, mtcars)
summary(fit1)
setwd("C:/Users/duy.bui/Documents/chillidrive")
source("dataPreprocess.R")
hist(trip_90$accel_aggregate)
hist(trip_90$brake_aggregate)
?hist
hist(trip_90$brake_aggregate)
hist(trip_90$accel_aggregate)
hist(trip_90$accel_aggregate, xlim = c(0, 1000))
hist(trip_90$accel_aggregate, xlim = c(0, 1000), break = 10)
hist(trip_90$accel_aggregate, xlim = c(0, 1000), breaks = 10)
hist(trip_90$accel_aggregate, xlim = c(0, 1000), breaks = 100)
hist(trip_90$accel_aggregate, xlim = c(0, 100), breaks = 100)
hist(trip_90$accel_aggregate, xlim = c(0, 2000), breaks = 100)
hist(trip_90$accel_aggregate, breaks = 100)
hist(trip_90$accel_aggregate, xlim = c(0, 2000), ylim = c(0, 5000), breaks = 100)
hist(trip_90$accel_aggregate, xlim = c(0, 1000), breaks = 100)
tem <- subset(trip_90, trip_90$accel_aggregate < 1000)
hist(temp)
hist(tem$accel_aggregate)
tem <- subset(trip_90, trip_90$accel_aggregate < 200)
hist(tem$accel_aggregate)
tem <- subset(trip_90, trip_90$accel_aggregate < 50)
hist(tem$accel_aggregate)
tem <- subset(trip_90, trip_90$accel_aggregate < 10)
hist(tem$accel_aggregate)
plot(x = trip_90$accel_aggregate, y = trip_90$trip_distance, type = "p")
hist(trip_90$trip_distance)
hist(trip_90$trip_distance, break = 1000)
hist(trip_90$trip_distance, breaks = 1000)
hist(trip_90$trip_distance, breaks = seq(0, 50000000, by = 100))
hist(trip_90$trip_distance, breaks = seq(0, 5000000, by = 100))
mean(trip_90$trip_distance)
mean(trip_90$trip_distance, na.rm = TRUE)
mean(trip$trip_distance)
mean(trip$trip_distance, na.rm = TRUE)
plot(trip_distance)
plot(trip$trip_distance)
temp <- trip[trip_distance < 6000,]$trip_distance
temp <- trip[trip$trip_distance < 6000,]$trip_distance
hist(temp)
hist(temp, breaks = 100)
hist(temp, breaks = 1000)
hist(temp, breaks = 50)
temp <- trip_90[trip_90$trip_distance < 6000,]$trip_distance
hist(temp, breaks = 50)
setwd("C:/Users/duy.bui/OneDrive/Courses/Practical Machine Learning/Assignment/PracticalMachineLearning_Assignment1")
library(caret)
pml.train <- read.csv(file = "pml-training.csv", header = TRUE, sep = ",")
pml.test <- read.csv(file = "pml-testing.csv", header = TRUE, sep = ",")
library(caret)
pml.train <- read.csv(file = "pml-training.csv", header = TRUE, sep = ",")
pml.test <- read.csv(file = "pml-testing.csv", header = TRUE, sep = ",")
pml.train <- pml.train[,which(unlist(lapply(pml.test, function(x)!all(is.na(x)))))]
pml.test <- pml.test[,which(unlist(lapply(pml.test, function(x)!all(is.na(x)))))]
excl.list <- c("X", "raw_timestamp_part_1", "raw_timestamp_part_2", "cvtd_timestamp", "user_name")
eliminateCol <- function(dat, excl.list){
excl.index = which(names(dat) %in% excl.list)
dat <- subset(dat, select = -excl.index)
dat
}
pml.train <- eliminateCol(pml.train, excl.list)
pml.test <- eliminateCol(pml.test, excl.list)
nzv <- nearZeroVar(pml.train, saveMetrics= TRUE)
nzv[nzv$nzv,]
excl.list <- c("new_window")
pml.train <- eliminateCol(pml.train, excl.list)
pml.test <- eliminateCol(pml.test, excl.list)
pmlCor <-  cor(pml.train[sapply(pml.train, function(x) !is.factor(x))])
highlyCor <- findCorrelation(pmlCor, cutoff = .75)
length(highlyCor)
pml.train <- pml.train[,-highlyCor]
pml.test <- pml.test[, -highlyCor]
trainIndex = createDataPartition(pml.train$classe, p=0.75, list=FALSE)
training = pml.train[ trainIndex, ]
testing = pml.train[ - trainIndex, ]
set.seed(33833)
modFit <- train(classe ~ ., method = "rf", data=training)
View(testing)
predicted <- predict(modFit, newdata = training)
table(predicted == training$classe)
predicted2 <- predict(modFit, newdata = testing)
table(predicted2 == testing$classe)
predicted3 <- predict(modFit, newdata = pml.test)
predicted3
pml_write_files = function(x){
n = length(x)
for(i in 1:n){
filename = paste0("problem_id_",i,".txt")
write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
}
}
pml_write_files(predicted3)
confusionMatrix(table(predicted, training$classe))
confusionMatrix(table(predicted2, testing$classe))
a <- confusionMatrix(table(predicted2, testing$classe))
a$overall
a$table
a$positive
a$byClass
a$dots
confusionMatrix(table(predicted, training$classe))$overall
confusionMatrix(table(predicted2, testing$classe))$overall
